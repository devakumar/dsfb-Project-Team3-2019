{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math  \n",
    "import copy\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.dummy           import DummyClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.ensemble        import GradientBoostingClassifier\n",
    "\n",
    "# Supporting functions from scikit-learn\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from sklearn.metrics         import roc_curve\n",
    "from sklearn.metrics         import roc_auc_score\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree            import export_graphviz\n",
    "from sklearn.decomposition   import PCA\n",
    "\n",
    "# for text processing\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# ignore some warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set a seed for replication\n",
    "SEED = 1  # Use this anywhere a stochastic function allows you to set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn=pd.read_excel(\"IPO_data_to_learn.xlsx\")\n",
    "df_predict=pd.read_excel(\"IPO_data_to_predict.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3330 entries, 0 to 3329\n",
      "Data columns (total 47 columns):\n",
      "Unnamed: 0            3330 non-null int64\n",
      "closeDay1             3215 non-null float64\n",
      "offerPrice            3330 non-null float64\n",
      "rf                    3057 non-null object\n",
      "egc                   3330 non-null bool\n",
      "html                  3330 non-null bool\n",
      "patRatio              2055 non-null float64\n",
      "city                  3329 non-null object\n",
      "issuer                3330 non-null object\n",
      "highTech              3330 non-null bool\n",
      "age                   3148 non-null float64\n",
      "exchange              3330 non-null object\n",
      "year                  3330 non-null int64\n",
      "industryFF5           3330 non-null object\n",
      "industryFF12          3330 non-null object\n",
      "industryFF48          3330 non-null object\n",
      "nUnderwriters         3330 non-null int64\n",
      "sharesOfferedPerc     3068 non-null float64\n",
      "totalProceeds         3330 non-null int64\n",
      "manager               3330 non-null object\n",
      "investmentReceived    1830 non-null float64\n",
      "amountOnProspectus    3330 non-null float64\n",
      "commonEquity          2651 non-null float64\n",
      "sp2weeksBefore        3330 non-null float64\n",
      "nasdaq2weeksBefore    3330 non-null float64\n",
      "dj2weeksBefore        3330 non-null float64\n",
      "blueSky               2002 non-null float64\n",
      "managementFee         2234 non-null float64\n",
      "commonEquity.1        2825 non-null float64\n",
      "bookValue             2912 non-null float64\n",
      "totalAssets           2973 non-null float64\n",
      "totalRevenue          2955 non-null float64\n",
      "netIncome             2938 non-null float64\n",
      "roa                   2938 non-null float64\n",
      "leverage              2954 non-null float64\n",
      "vc                    3330 non-null bool\n",
      "pe                    3330 non-null bool\n",
      "prominence            3330 non-null int64\n",
      "nVCs                  2001 non-null float64\n",
      "nExecutives           1901 non-null float64\n",
      "priorFinancing        1913 non-null float64\n",
      "ipoSize               2014 non-null float64\n",
      "reputationLeadMax     3330 non-null float64\n",
      "reputationLeadAvg     3330 non-null float64\n",
      "reputationSum         3330 non-null float64\n",
      "reputationAvg         3330 non-null float64\n",
      "nPatents              3330 non-null int64\n",
      "dtypes: bool(5), float64(28), int64(6), object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_learn.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: We observe that there 47 columns out of which 39 are numeric/bool and 8 are text type. We also notice that there are some missing data in many fields. \n",
    "\n",
    "Now we look at the detailed profile of the dataFrame using pandas profiling. (The report is provided in HTML along with the submission. Observations related to the report are given below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file.profile_report()\n",
    "profile = pandas_profiling.ProfileReport(df_learn)\n",
    "profile.to_file(outputfile='learn_data_profile_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations from the profile report**\n",
    "\n",
    "* Presence of missing values (Either drop or process the missig fileds)\n",
    "* High correlation among 5 fields (May be ignored or Use PCA to reduce the dimentionality)\n",
    "* Different scales, ranging from 0 to 1e9. (Need to normalize the data)\n",
    "* Missing outcome: offerPrice(3.5%) and closeDay1(3.5%). Since there is no outcome, it may not be useful to use this data, may be dropped.\n",
    "* Only 22% of the companies are marked emerging growth companies. (Possibility of bias?)\n",
    "* Most of the companies are listed in NASDAQ(2368), followed by NYSE(895)\n",
    "* Data is present from 1996 to 2018 (More data in the late 90s, but data is well spread across years)\n",
    "* Five fields that are skewed (totalProceeds, InvestmentReceived, commonEquity1, totalRevenue, nPatents)\n",
    "* 19 fileds out of 47 have missing entries. Highest missing entries in investmentReceived(45%) followed by nExecutives, priorFinancing, nVCs, patRatio, managementFee(32.9%) in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile report for the prediction data\n",
    "profile = pandas_profiling.ProfileReport(df_predict)\n",
    "profile.to_file(outputfile='predict_data_profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NASDQ    2368\n",
       "NYSE      895\n",
       "AMEX       67\n",
       "Name: exchange, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learn['exchange'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Equipment, Telephone and Television Transmission                                         1122\n",
       "Other                                                                                              898\n",
       "Healthcare, Medical Equipment, and Drugs                                                           621\n",
       "Consumer Durables, NonDurables, Wholesale, Retail, and Some Services (Laundries, Repair Shops)     393\n",
       "Manufacturing, Energy, and Utilities                                                               296\n",
       "Name: industryFF5, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learn['industryFF5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Equipment -- Computers, Software, and Electronic Equipment    945\n",
       "Healthcare, Medical Equipment, and Drugs                               621\n",
       "Finance                                                                483\n",
       "Other                                                                  462\n",
       "Wholesale, Retail, and Some Services (Laundries, Repair Shops)         271\n",
       "Name: industryFF12, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learn['industryFF12'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Services          845\n",
       "Pharmaceutical Products    409\n",
       "Trading                    221\n",
       "Electronic Equipment       190\n",
       "Retail                     158\n",
       "Name: industryFF48, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learn['industryFF48'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Will probably need to only keep 1 of these, maybe FF12?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_learn = df_learn.rename(columns={\"commonEquity\":\"commonEquity1\",\"commonEquity.1\":\"commonEquity2\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Age is the age of the firm. Should replace mising values by the mean? Are the zeros indicating new firms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.184561626429478\n",
      "0    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_learn['age'].mean())\n",
    "print(df_learn['age'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([w for w in file['age'] if w>100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Is it possible to have so much old companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.0 12916.115884115885\n"
     ]
    }
   ],
   "source": [
    "print(file['blueSky'].median(), file['blueSky'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Should do something with *blue sky* missing value: need to decide if really useful and, if it is, how to fill it. mean, median or mean between 1sr and 3rd quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-process on Risk Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English Stopwords from NLTK & Extend the stop word list\n",
    "SW = stopwords.words('english')\n",
    "SW.append('risk')\n",
    "SW.append('factors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08198198198198198"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks how many percent of risk facor are NaN values\n",
    "df_learn['rf'].isna().sum()/len(df_learn['rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file them with a blank\n",
    "df_learn['rf'] = df_learn['rf'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean punctuation from  given text\n",
    "def clean_punctuation(txt):\n",
    "    return str(txt).replace(\",\", \" \").replace(\".\", \" \").replace(\":\", \" \").replace(\";\", \" \").replace(\"?\", \" \").replace(\"!\", \" \").replace(\"\\\\\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RISK FACTORS You should carefully consider the...\n",
       "Name: rf, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to clean the rf column\n",
    "df_learn['rf'] = df_learn['rf'].apply(clean_punctuation)    \n",
    "df_learn['rf'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean some given text\n",
    "def clean_re(txt):\n",
    "    txt = re.sub(\"[+]\", \" \", txt)\n",
    "    txt = re.sub(\"[&]\", \" \", txt)\n",
    "    txt = re.sub(\"\\s \\s\", \" \", txt)\n",
    "    txt = re.sub(\"\\s \\s \\s\", \" \", txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RISK FACTORS You should carefully consider the...\n",
       "Name: rf, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply clean_re() to all features\n",
    "df_learn['rf'] = df_learn['rf'].apply(clean_re)    \n",
    "df_learn['rf'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to remove stopwords\n",
    "def clean_sw(txt):\n",
    "    li = list(txt.lower().split(\" \"))\n",
    "    txt = [word for word in li if word not in SW]\n",
    "    return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    carefully consider following information conta...\n",
       "Name: rf, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to remove stopwords\n",
    "df_learn['rf'] = df_learn['rf'].apply(clean_sw)    \n",
    "df_learn['rf'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to wrap simple_preprocess() from gensim\n",
    "def sp(txt):\n",
    "    return simple_preprocess(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [carefully, consider, following, information, ...\n",
       "Name: rf, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simple_preprocess() to all features\n",
    "df_learn['rf'] = df_learn['rf'].apply(sp)    \n",
    "df_learn['rf'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet') #downloading wordnet to use lemmatizer\n",
    "lmtz=nltk.stem.WordNetLemmatizer()\n",
    "# Write a lemmatization function based on nltk.stem.WordNetLemmatizer()\n",
    "def lemmatiz(txt):\n",
    "    return [lmtz.lemmatize(mot) for mot in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [carefully, consider, following, information, ...\n",
       "Name: rf, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply lemmatize_text() to all features  \n",
    "df_learn['rf'] = df_learn['rf'].apply(lemmatiz)    \n",
    "df_learn['rf'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.copy(df_learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'].fillna(data['age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['blueSky'].fillna(data['blueSky'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to drop the data corresponding to missing or negative values of 'closeDay1' as this feature is very important and so replacing missing values may lead to huge misinterpretation. Moreover it corresponds to only 3.5% of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[\"closeDay1\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3215, 47)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#data.profile_report()\n",
    "\n",
    "Referring to the profile report generated, attached as HTML along with submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some features are highly correlated, so we will use PCA to remove the redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
